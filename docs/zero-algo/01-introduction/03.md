# 第 1.3 节 时间复杂度与空间复杂度

<!-- ![...一整节的内容，放在开始就可以了）.mp4](fb5da98e-df02-4d05-b57a-915fa74223eb) -->

---

![image-20200716094906792](https://tva1.sinaimg.cn/large/007S8ZIlgy1ggskoccuz1j31x80s6tf3.jpg)


我们在上一节最后有介绍：一个算法是否正确，至少要执行一遍看看。这一节我们介绍如何评估一个算法性能的好坏。评估一个算法性能好坏通常有 2 个指标，**执行时间**和**内存消耗**。通常在服务端领域我们更关注的是执行时间，这是因为内存消耗可以回收，并且用户不会关心服务端那边执行一个程序用了多少空间。我们在给「力扣」提交代码的时候，会看到提交记录里显示一共有多少测试用例，并且通过了多少测试用例。

![image-20200709145643818](https://tva1.sinaimg.cn/large/007S8ZIlgy1ggkq8bis8gj31te0cuq4m.jpg)

这样的评估算法性能的方法叫做：事后评估法。事后估计法由于客观条件的限制，测量的结果不会特别准确。这是因为：

+ 测量的结果与输入数据的规模、使用编程语言、系统当时是否有其它任务执行等很多因素有关；
+ 测量这件事情本身有误差，一个更靠谱的方式是多次测量求平均。

测不准是客观事实，而采用更多的是一种**事前估计**的方法，这种方法叫做大 $O$ 复杂度表示法（大 $O$ 读作：大欧、big 欧）。与此相关的两个概念是「时间复杂度」与「空间复杂度」。

很多算法教材上都有给出非常准确的「时间复杂度」与「空间复杂度」的定义，我们在这里先给出一些感性上的理解。「时间复杂度」与「空间复杂度」的概念不要求在一开始的时候弄清楚，绝大多数面试和笔试不会直接考察复杂度的定义，在后续的课程在写完一段代码以后，我们都会和大家一起分析所写代码的「时间复杂度」与「空间复杂度」。

---

## 以「动态的」眼光看待时间复杂度与空间复杂度

「时间复杂度」与「空间复杂度」的前面还有一个词，叫「**渐进**」，它表示的是：算法在输入数据的规模成倍增长的时候，相应的时间消耗多增长了多少。例如数学家高斯计算 $1$ 到 $100$ 的和，如果按照普通加法一个一个加起来来算，计算 $1$ 到 $100 0000$ 消耗的时间一般来说会更多，而高斯使用的等差数列前 $n$ 项和公式，就可以保证当问题规模成倍扩大的时候，计算资源的消耗不受太大影响。


```Java []
int n = 100;
int sum = 0;
for (int i = 1; i <= n; i++) {
    sum += i;
}
System.out.println(sum);
```

说明：这个算法执行的操作数与输入规模 $n$ 线性相关，$n$ 越大，执行的操作数越多，消耗时间越长。


```Java []
int n = 100;
int sum = (1 + n) * n / 2;
System.out.println(sum);
```

说明：这个算法执行的操作数与 $n$ 无关。不论 $n$ 多大，程序的执行的次数都是常数次的。当然 $n$ 特别大的时候，可能会发生整形溢出，这是另一个话题了。

希望大家能够通过这个最简单的例子，理解**渐进**时间复杂度这个概念。「复杂度」不能单看我们所写的代码对于 1 个、2 个测试用例的结果，而应该看输入规模发生成倍数变化，一直到很大很大的时候，相应的时间和空间的消耗增加了多少。

我们在上面的代码中并没有具体说常数次到底执行多少次，这一点并不重要。大 $O$ 表示法是一种事前估计法。由于程序的执行时间和很多因素都有关，并且还有测不准的客观原因存在，因此我们没有必要把一段代码真正执行了多少步给计算出来。计算准确的函数的执行步数，首先是没有必要的，在工程上用处不大；其次也不便于工程师之间的交流，复杂的表达式不能体现不同算法的差异。

时间复杂度的计算只需要得出一个大概的结果。估算的意义是：

+ 便于不同的算法进行比较，把性能表现差不多的算法归为一类；
+ 更重要的是：在程序员编码的过程中可以进行自我检查和优化。有些时候，为了先实现这个功能，我们会先写一个粗略的版本，好让这个程序能够正确的运行，但是这个粗略的版本很可能是效率不高的。进行复杂度的估算，可以帮助我们自我检查是不是还有可以优化的地方。有些库函数的代码虽然只有一行，但复杂度可能是线性的。这样的代码或许就不适合出现在循环体当中。

综上，很多时候我们只需要给一个近似的结论就可以了。这一点思想其实还蕴含在我们编码的过程中，很多时候我们没有必要做到理论上最好，而更多时候要有**工程化**的思维，也就是：真正去做这件事情的时候，最「合适」的方法，就是最好的办法。例如只需要计算 $1$ 到 $100$ 的和，写一个 `for` 循环即可，甚至有可能更好。在数据规模不大的情况下，最简单的方法很可能是最好的方法。

---

## 计算时间复杂度与空间复杂度

首先要强调的一点是：时间复杂度的计算（估算）只有在输入规模特别大的时候才有意义。「输入规模特别大」往往是我们初学的时候不可感知的。大 $O$ 表示法是一种事前估计法，得到一个函数表达式，它表示了：随着输入规模的扩大，程序的执行消耗会扩大的程度。这个程度不是直接从表达式上直接看出来的，需要在一个动态增加的过程中去理解程序的执行消耗会扩大的程度。

在数据规模较小的时候，不同时间复杂度的执行操作数，我们把它们画在同一个直角坐标系中，可以看出它们增长的趋势。

![image-20200729142024172](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7tkmvbckj30us0smtc8.jpg)

上面的直角坐标系里，横轴 $n$ 表示数据的规模，纵轴 $y$ 表示程序的运行时间。但只在小规模测试用例下观察复杂度的趋势是不准确的。现在我们把数据规模扩大到 $100000$，为了使得这些函数容纳在同一个直角坐标系中，我们对复杂度较高的函数做了成比例的缩小（把对数的底从 $2$ 改成 $10$ ，$n^2$ 缩小到原来的 $\cfrac{1}{10000}$  ）。

![image-20200729142046596](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7tl0qmncj31n40fmae0.jpg)

$y =\log_{10} n$  和 $y = 1$ 这两条直线由于显示数据的数量级的原因，不能体现出差异。我们单独绘制出这两个函数的图形：

![image-20200714173156722](https://tva1.sinaimg.cn/large/007S8ZIlgy1ggqmtc5j1sj31ha0e63ze.jpg)

可以看到： $y =\log_{10} n$  这个函数的图形随着 $n$ 的成倍增长，纵轴数值的增长较缓慢（这已经是一种很好的时间复杂度了），到了 $100000$ 这个数量级，函数值也才到 $5$，我们接下来要学习的算法中，「二分查找」就具有这样的时间复杂度：随着输入数据规模的增加，函数的执行次数增长较缓慢。我们接着看：

+ $y = 1$ 的函数图像表示了程序的运行时间与输入数据的规模无关；
+ $y = \cfrac{1}{10000}n^2$ 随着 $n$ 的成倍增长，函数值也成比例地增长，这样的时间复杂度是性能相对较差的，这样的算法常常是「朴素解法」和「暴力解法」；
+  $y = n \log n$ 的函数图像一开始的时候在 $y = \cfrac{1}{10000}n^2$ 的上方，但是在 $n = 50000$ 以后，$y = \cfrac{1}{10000}n^2$ 的函数图像在 $y = n \log n$ 的上方，我们认为  $y = \cfrac{1}{10000}n^2$  的表示的算法复杂度较高。

由此我们可以看出：研究更大规模的输入数据与算法操作数的关系是更有意义的。下面我们列出一些复杂度的计算规则。

---

## 常见的时间复杂度计算规则

### 1. 常数加法系数看做 $0$

一段程序必须要做的操作（常数次操作）不纳入复杂度的计算。一般而言，常数次操作都不会是造成程序性能瓶颈的原因。

### 2. 对于一个多项式，只保留最高次幂的项，并且乘法系数化简成 $1$

常见结论：

- 一次遍历，里面不再有循环的操作，时间复杂度是 $O(N)$。也就是说，我们把输入数据里所有的元素看一遍，就可以得到结果。这样的算法称为具有线性复杂度的算法。

- 双重循环，内外层都与输入规模相关的时候，时间复杂度是 $O(N^2)$  。 $O(N^2)$ 级别的复杂度我们会在第 3 章「选择排序」和「插入排序」章节向大家介绍。

注意：有些算法形式上是双重循环，但事实上，程序只遍历了数组一次或者若干次，这样的算法时间复杂度为 $O(N)$，以后遇到这一类问题的时候再向大家说明。

### 3. 对数或者是含有对数乘法因子的项，对数底都看作 $2$

对数级别的时间复杂度，常见且典型的算法是「二分查找」，时间复杂度的表达式为 $O(\log N)$ 。

下面我们介绍为什么底数都看成 $2$。如果一个算法计算出来的输入规模 $N$ 与算法执行次数的表达式为 $\log_{10} N$ ，那么根据高中数学学习过的对数换底公式：

$$
\log_a{b} = \cfrac{\log_c{b}}{\log_c{a}}
$$
有 $\log_{10}{N} = \cfrac{\log_2{N}}{\log_2{10}} = \cfrac{1}{{\log_2{10}}}{\log_2{N}}$ ，常数乘法系数项 $\cfrac{1}{\log_2{10}}$ 视为 $1$，因此写  $O(\log_{10} N)$  等价于 $O(\log_{2} N)$，统一记为 $O(\log N)$ 。

---


## 绝大多数时候关注最坏情况

一个程序最坏的情况我们都可以接受，那么最好的情况当然是没有问题的，这就像我们常说的「做最好的准备，最坏的打算」一样。

当然也有例外：如果一个程序，我们采用了一些手段，导致了最坏情况出现的概率大大降低，那么我们会约定俗成地将时间复杂度定义成「一般情况」，也就是说「最坏情况」几乎不可能发生的话，我们就把「一般情况」当成「最坏情况」。

---

## 时间复杂度的数学定义

有了上面的描述，我们再来看《算法导论》这本书里「时间复杂度」的数学定义：$O(g(n)) = \{ f(n)$：存在正常量 $c$ 和 $n_0$，使得对所有 $n \ge n_0$，有 $0 \le f(n) \le cg(n)$。

![01-03-03.009](https://tva1.sinaimg.cn/large/007S8ZIlgy1ggsmy7calvj31hc0u078t.jpg)

$O$ 表示的是一个函数的渐进上界。说上界，是因为我们要考虑最坏的情况，最坏的情况我们可以接受，才认为我们设计的算法是有效的，它不是一个具体的表达式，只是一个记号；

在 $O$ 里面的函数表达式是一个简化过的表达式，这样的函数表达式近似地表示了具体的计算结果，这个结果的计算我们上面也向大家介绍了，是一个「抓大放小」的粗略计算的结果。

这个概念写在这里不是要大家记住，绝大多数情况下面试不会考时间复杂度的定义。从语言描述上特别像《高等数学》里「极限」的概念，假设准确计算出来的时间复杂度的表达式是 $f(n)$，但我们找到了一个表达式比较简单的函数 $g(n)$，使得我们当前写的算法的时间复杂度与 $g(n)$ 的比，在 $n$ 趋于无穷的时候，$f(n)$ 与 $g(n)$ 的比是一个常数，那么我们就用 $g(n)$ 来近似地表示准确值 $f(n)$，等价地有下面的式子成立：

$$
\lim_{n \to \infty} \cfrac{f(n)}{g(n)} <= c
$$

如果大家还记得在《高等数学》里学习的知识的话，一定还记得「等价无穷小」这个名词，这里时间复杂度的定义其实就跟这个「等价无穷小」类似。在 $n$ 特别大的时候，在工程实践中，认为它们等价。


现在大家再回过头看「常见的时间复杂度计算规则」相信就不难理解了：在计算极限的时候，两个多项式的极限，只取决于最高次幂的项，以及它们的系数。

---

## 对「时间复杂度」与「空间复杂度」的误解

### 误解 1：「时间复杂度」等于「运行时间」

之前我们说过，测量这件事情，多次求测量求平均值的结果才可靠。不过一般的测评系统，为了避免资源的浪费和尽快反馈运行结果，都只把所有的测试用例执行一次。因此，运行时间具有一定随机性，要想得到相对准确的结果其实很简单，就是多执行几次，看看自己的算法运行时间是不是真的稳定在一个水平上。

### 误解 2：需要尽可能地优化算法

在编程领域，同样存在设计过渡的问题，例如，我们在编写程序的时候，有一些常数级别的优化是没有必要的，一个最典型的例子就是取中点：

```Java []
int mid = (left + right) / 2;
```

这种写法其实有几个等价的写法：

`int mid = left + (right - left) / 2;`  这个写法，是为了避免 `left + right` 在整型范围内溢出，导致结果错误。但是在很多问题中，`left` 和 `right` 表示的数组的下标，测试用例里下标到了接近整型最大值的时候，才会出现这种极端的情况，我们写成这个样子通常只是出于习惯和保守估计，绝大多数情况下，是不会开那么大的数组去完成一个任务。

```Java []
int mid = left + (right - left) >> 1;
```

` / 2` 写成 `>> 1` 右移 1 位确实在理论上是能够快一些的，但其实这样的优化，在现代的编译器里已经为我们做了。因此我们作为程序员没有必要在上层编码的时候这么做，并且这样的写法在 C++ 里面还有一个优先级顺序的问题，即使写位运算的写法会提速，这种提速的也是不可感知的，我们写代码需要尽可能表达我们的逻辑本来的意思。

还有一种写法

```Java []
int mid = (left + right) >>> 1;
```

是我在 Java 源代码里看到的，这样的写法在 `left + right` 整形溢出的时候，依然可以保证结果正确，这是因为 `>>>`  是无符号右移，在 `left + right` 发生整形溢出的时候，右移以后高位补 $0$ ，所以能够保证结果正确，但是这样的写法不具有迁移性，真正我们在编写项目代码的时候，无符号右移 `>>>` 是很少用到的。

一般而言，我们写代码，写 `int mid = (left + right) / 2;` 或者 `int mid = left + (right - left) / 2; `  都可以，用位运算就有设计过渡的问题，在测评系统写这样的代码问题不大，但是工程级别的代码就不建议这样写。

代码只是我们解决问题的工具，写代码能够高效地被他人和自己理解，是更重要的。这是因为工程的代码会有经常修改和调试的问题，表意清晰就很重要。

### 误解 3：对空间复杂度过于在意

这一点的提出基于这样一个事实：「时间复杂度」和「空间复杂度」通常不能同时最优，因此就有两种优化的思路：「空间换时间」和「时间换空间」。

但是一般来说，用户更关心一个程序的执行效率，假想一个算法，要经过很长时间的运行才能得到结果，那必然是很影响用户体验的，用户因此浪费的时间是不可挽回的。

但是用户并不关心一个算法在后台到底占用了多少空间，一方面是这些空间成本随着硬件的优化来说变得越来越廉价，再者空间是可以被回收的，这一块内存执行完成以后，还可以接着用于执行下一段程序。因此，必要的空间不能省。

一个极端的例子是「汉诺塔」这个程序，正是因为限制使用了空间，会导致在数据规模变大以后， 程序的执行时间会呈指数型的增长。因此我们的建议是：一个程序，应该尽量朝着「空间换时间」的思路去思考。用「时间换空间」通常来说是费力不讨好的。如果你说一个算法时间复杂度你做到了最优，那一定会得到一个好评，但你说空间复杂度最优，很多时候是要打一个问号的，通常来说「暴力解法」的空间复杂度就是最优。很少的问题能做到时间和空间同时最优，这些问题通常是挖掘了题目条件的深层性质。

---

## 时间复杂度和空间复杂度的其它话题

在初学的时候可以不用计算那么准确，在看他人题解或者是自己编写程序的时候，都要有意识的看一下关于时间复杂度的解释，但不必深入细节，只要感性地理解结论就可以了。

「力扣」的官方题解是一定会解释「时间复杂度」是如何计算的，可以参考进行学习。

对于一些「教材」和「经典书籍」，都会花很大的篇幅去论述「时间复杂度」的严格计算与证明，在初学的时候乃至以后很长的一段时间内，都是不需要掌握的，除非我们是专门做理论的研究，也就是我们写了一个算法，然后要将这个算法公开发表成学术论文，那么「时间复杂度」的严格计算才是有必要弄清楚的；

时间复杂度还有其它的记号，但几乎在工程领域我们只谈大 $O$ 记号，其它记号可以略作了解，但不必深入。

复杂度的分析还有「均摊复杂度分析」和「震荡时间复杂度分析」，它们都是对特殊情况下的时间复杂度分析，也就是我们之前提到的，那个最坏的情况不是每时每刻都出现，采用「均摊复杂度分析」和「震荡时间复杂度分析」是更合理的，依然是「凡事都有例外」，这一点大家有个印象即可，我们以后还会再谈；

复杂度的分析还有一个有利的工具，叫「**主定理**」，用于分析递归函数的时间复杂度，「主定理」我们只需要知道结论，会用即可，我们会在后面的课程中介绍「主定理」的应用。

总的来说，「时间复杂度」和「空间复杂度」这两个概念是需要在我们刷题的过程中，慢慢去体会的，这一小节的内容仅仅只是给大家开个头。

---

## 练习

1. 查阅资料，了解「均摊复杂度分析」和「震荡时间复杂度分析」以及应用；
2. 查阅资料，了解「主定理」以及应用。

---

## 总结

1. 时间复杂度的概念很重要，除了一些复杂的算法，例如「带剪枝」的「回溯算法」，复杂度的分析很复杂，一般情况下不要求分析，一般情况下面试的时候都会涉及复杂度分析；
2. 时间复杂度需要动态去理解，看到一个复杂度的表达式，我们需要想到：当输入规模扩大多少倍的时候，程序的执行时间相应扩大了多少倍；
3. 对于时间复杂度的优化比空间复杂度重要得多；
4. 复杂度分析还有「均摊复杂度分析」和「震荡时间复杂度分析」，我们遇到具体问题的时候再和大家做介绍；
5. 复杂度分析还有一个非常重要的理论：「主定理」，我们也会在后续的课程里向大家介绍。

<br>
> 友情提示：复杂度分析是贯彻我们整个「算法与数据结构」学习始终的，大家在学习的时候需要有一种工程化的思维。在初学的时候，不必强求自己马上能理解复杂度这个概念。在以后的应用中，也不需要分析得特别具体。

---

这一节的内容就是这样，感谢大家。