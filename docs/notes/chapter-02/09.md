# 【算法日积月累】9-堆与优先队列

这部分我们介绍一种新的数据结构堆（Heap），“堆”是实现“优先队列”的一个高效的数据结构。首先，我们来认识“优先队列”。

## 优先队列（**priority** queue）

“优先队列”是从下面的这种场景中抽象出来的数据结构。

> 例：班级里要选一名同学代表全班参加程序编程竞赛，此时我们只会关心第 1 名是谁，第 1 名本人不想参赛了，或者说第 1 名因为其它因素不符合参考资格，我们才考虑第 2 名，但也是从剩下的那些同学中挑出第 1 名。即当前我们只关心当前“最优”的那个元素，第 2 名及其以后的同学都不考虑了。

“优先队列”相对于“普通队列”而言。“普通队列”的性质是“先进先出，后进后出”。“优先队列”由元素的**优先级**决定出队的顺序。

| 普通队列                                       | 优先队列                                                     |
| :--------------------------------------------- | :----------------------------------------------------------- |
| 先进先出，后进后出。由进入队列的时间顺序决定。 | 出队顺序与入队顺序无关，只与队列中元素的优先级有关，优先级最高的元素最先出队。 |

### 更多优先队列在生活中的例子

“优先队列”更多地应用于动态的情况，即数据不是一开始就定好的，而是随时都有可能来新的数据，此时新数据与旧数据在一起选出“优先级”最高的那个元素。比如以下场景，重点理解“动态执行”这个概念：

1、医院看病：重症患者往往优先治疗，即使他是后来者；

2、操作系统：选择优先级最高的任务执行；

3、上网：服务端依次回应客户端的请求：通常也是使用优先队列，优先级高的客户端优先响应；

下面是一个静态的例子。

> 例：从 $1000000$ 个数中选出最大的 $100$ 个数。

这个问题我们抽象成数学表达就是：在 $N$ 个元素中选出前 $M$ 个元素。

1、如果我们使用之前学习的排序算法，时间复杂度为：$O(N \log N)$，即先排序，再取出前 $M$ 个元素。此时，这个问题的时间复杂度完全由使用的排序算法决定。

2、如果我们使用优先队列，那么解决该问题的时间复杂度为：$O(N \log M)$。与使用排序算法不同之处在于，我们只要维护有 $M$ 个元素的数据结构就可以了。在这一章的末尾我们将要解决这样的问题。

## 优先队列的主要操作

“优先队列”是一种抽象的数据结构，有两种“优先队列”。一种“优先队列”每次可以从中拿到我们定义下优先级“最高”的元素，即“最大堆”、“大顶堆”、“大根堆”，另一种“优先队列”每次可以从中拿到我们定义下优先级“最低”的元素，即“最小堆”、“小顶堆”、“小根堆”。如果没有特别说明，我们下文所指的“优先队列”都是指每次可以拿到优先级“最高”元素的优先队列。

“优先队列”的主要操作有：

1、入队

2、出队：优先队列的一个重要特点是：出队的时候总是取出优先级最高的那个元素。

如果不考虑时间复杂度，“优先队列”可以有以下两种实现方式：“无序数组”和“有序数组”。

实现1：无序数组。放入的时候，直接放在数组的末尾，时间复杂度：$O(1)$。每次拿出元素之前，我们都排个序，或者像“选择排序”那样，把最大的那个拿出去就好了，时间复杂度是：$O(n)$。

实现2：有序数组。每次放入元素的时候，我们都排个序，像插入排序内层循环那样，保持数组的有序性，时间复杂度 $O(n)$，把最大的那个拿出去 $O(1)$。

伟大的计算机科学家平衡了入队和出队这两个操作的时间复杂度，这种数据结构就是堆。

### 三种数据结构对于实现优先队列的时间复杂度的比较

| 实现优先队列的数据结构 | 入队操作    | 出队操作 |
| :------- | :---------- | :------- |
| 普通数组 | $O(1)$      | $O(n)$   |
| 顺序数组 | $O(n)$      | $O(1)$   |
| 堆       | $O(\log n)$ | $O(\log n)$ |

说明：$\log n$ 表示以 $2$ 为底的 $n$ 的对数。

在 $N$ 个元素中选出前 $M$ 个元素。使用普通数组或者顺序数组，最差的情况是 $O(N^2)$，使用堆可以将时间复杂度降到：$O(N\log M)$。事实上，时间复杂度是 $O(N^2)$ 与 $O(N\log M)$ 的差异巨大的。理解这个事实是我们掌握堆以及相关算法的基础，正是因为使用堆这种数据结构，提高了我们算法的执行效率，我们才有必要来研究堆，使用堆。

我们发现，不管是“入队”还是“出队”，总有一个操作得把“优先队列”中的元素都看一遍。而“堆”就是这样一个数据结构，能把 $O(n)$ 降到 $O(\log n)$。

综上所述，**“堆”是实现“优先队列”的高效的数据结构**。“堆”有“最小堆”和“最大堆”，和上面一样，如果没有特别说明，我们下文所指的“堆”都是指“最大堆”。

## 什么是“堆”

通过上一小节的介绍，我们可以看到堆的入队和出队的时间复杂度都是 $O(\log n)$ ，因此我们可以猜测它的形状看起来像是一棵树一样。

形如下面形状的一个结构就是“最大堆”。

![堆与优先队列-1](http://upload-images.jianshu.io/upload_images/414598-d59ab650f181c4f1.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/600)

### “最大堆”的性质：

首先，**“最大堆”是一棵“完全二叉树”**。

> **完全二叉树：从形状上看，除了最后一层之外，其它层结点的数量达到最大值，并且最后一层的结点全部集中在左侧。**

“完全二叉树”的特点是，可以使用一个数组保存“完全二叉树”，而不必引入树形结构。这样既可以利用数组元素可以快速访问的特点，又让结点和结点之间形成了“父”与“子”的结构关系。

其次，任意一个结点，如果有孩子结点的话，孩子结点的值一定不会大于父亲结点的值。

如果一个数组中的元素，有如上特点，我们称之为堆有序。堆有序不是我们通常理解意义上的“升序”或者“降序”。如果把数组排成“完全二叉树”的样子，且满足第 2 条，这个数组就是“堆有序”。这里要注意的是，通常我们数组的 $0$ 号索引不使用，从 $1$ 号索引开始使用，这只是一种习惯，因为这么做父子结点的索引关系更“好看”一些，仅此而已。到从 $0$ 号索引开始使用的堆也是可以的。

下面我们从索引从 1 号开始，自上到下、自左到右，标记，即显示成结点的旁边黑色的数字，我们不难发现这些数字的排列形成的规律。**正是因为“堆”是一棵“完全二叉树”，有如下的规律，我们才可以很方便地索引数组中的位置，这就是我们为什么使用数组而不是使用树来实现堆。**

![堆与优先队列-2](http://upload-images.jianshu.io/upload_images/414598-605117ff63eb6c84.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/600)

规律1：一个结点的左结点（如果有的话）的索引是这个结点的编号的 $2$ 倍；

规律2：一个结点的右结点（如果有的话）的索引是这个结点的编号的 $2$ 倍 $+ 1$。

从子结点索引找到父结点索引：${\rm parent(i)}=\cfrac{i}{2}$，注意这里不能整除的时候需要向下取整。

从父节点索引找到两个子结点索引：${\rm left\ child = 2 \times i}$，${\rm right\ child} = 2 \times i+1$。

这个两条性质不用记，我们只要拿一张纸，画一个像上面一样图，就非常清楚了。到这里为止，我们可以先写出“最大堆”的框架。

Python 代码：

```python
class MaxHeap:
    def __init__(self, capacity):
        # 我们这个版本的实现中，0 号索引是不存数据的，这一点一定要注意
        # 因为数组从索引 1 开始存放数值
        # 所以开辟 capacity + 1 这么多大小的空间
        self.data = [None for _ in range(capacity + 1)]
        # 当前堆中存储的元素的个数
        self.count = 0
        # 堆中能够存储的元素的最大数量（为简化问题，不考虑动态扩展）
        self.capacity = capacity

    def size(self):
        """
        返回最大堆中的元素的个数
        :return:
        """
        return self.count

    def is_empty(self):
        """
        返回最大堆中的元素是否为空
        :return:
        """
        return self.count == 0
```

Java 代码：

```java
public class MaxHeap {

    private int[] data;
    private int count; // 堆中真实元素的个数

    public MaxHeap(int capacity) {
        // 开辟数组空间（整个数组存储从索引 1 开始）
        data = new int[capacity + 1];
        count = 0;
    }

    public int size() {
        return count;
    }
    // 当前堆中的元素个数是否为 0
    public boolean isEmpty() {
        return count == 0;
    }
}
```

下面我们介绍如何保持“最大堆”数组的堆有序的性质。

## 最大堆的第 1 个重要操作：向一个“最大堆”中添加元素

向“最大堆”中添加一个元素，对应优先队列中“入队”这个操作，同时还要保持“最大堆”的性质，即根元素是“最大堆”中最大的元素，并且除了根结点以外任意一个结点不大于它的父亲结点。这个操作叫做 `shift up` 。

向“最大堆”中的添加元素的时候，首先添加在数组的末尾，这是因为移动次数最少，然后进行调整，使得调整后的数组仍然满足最大堆的性质。

具体步骤如下：

1、新加的元素放在数组的末尾；

2、新加入的元素调整元素的位置：只与父结点比较（不必与兄弟孩子比较），如果比父结点大，就交换位置，否则，可以停止了，这个元素就放在当前位置。

为什么我们要在数组的末尾添加一个元素呢？可不可以在开头、中间？既然我们使用数组来实现堆，对数组添加一个元素来说，实现复杂度最低的操作就是在数组的末尾添加元素，如若不然，要让数组中一部分的元素逐个后移，**因此在数组的末尾加入元素是最自然的想法**。但是在数组的末尾添加了一个元素，此时的数组就不满足堆的定义（性质），我们需要进行一系列的操作，去维护堆的定义（性质）。

### 如何维护堆的定义和性质：通过 `shift up` 把新添加的元素放置到合适的位置

在数组的最后位置添加一个元素，新加入的元素只和父结点比较大小（无须和它的兄弟结点比较），只要比父结点大（严格大于），就往上走，**否则停止，这个新添加的元素就放置在合适的位置，同时也调整了部分元素的位置**。循环这样做，这样的过程叫做 `shift up`，`shift up` 也叫 `swim`，是“上浮”的意思。

Python 代码：

```python
def __shift_up(self, k):
    # 有索引就要考虑索引越界的情况，已经在索引 1 的位置，就没有必要上移了
    while k > 1 and self.data[k // 2] < self.data[k]:
        self.data[k // 2], self.data[k] = self.data[k], self.data[k // 2]
        k //= 2
```

有索引就必须要考虑索引的边界问题，就是这里说的 `h > 1`，因为当 `h = 1` 的时候，元素已经在堆顶， `Shift Up` 操作没有意义。

另外和“插入排序”的优化一样，先存一下这个可能会上移的元素，通过逐层赋值，实现与逐层交换上移等价的操作。

Python 代码：`shift up ` 的过程可以转化为多次赋值

```python
def __swim(self, k):
    # 上浮，与父结点进行比较
    temp = self.data[k]
    # 有索引就要考虑索引越界的情况，已经在索引 1 的位置，就没有必要上移了
    while k > 1 and self.data[k // 2] < temp:
        self.data[k] = self.data[k // 2]
        k //= 2
    self.data[k] = temp
```

`shift up` 是 `insert` 的一个子过程，有了 `shift up` ，`insert` 函数就可以很快写出来 ：

Python 代码：

```python
def insert(self, item):
    if self.count + 1 > self.capacity:
        raise Exception('堆的容量不够了')
    self.count += 1
    self.data[self.count] = item
    # 考虑将它上移
    self.__swim(self.count)
```

## 最大堆的第 2 个重要操作：向从一个最大堆中取出元素

根据堆有序的性质，根结点是堆（数组）中最大的元素，即索引为 $1$ 的元素。从最大堆中取出一个元素，即是取出根结点元素，同时还要保持最大堆的性质。

根结点取出以后，$1$ 号索引位置为空，于是我们将当前数组的最后一个元素放到 $1$ 号索引的位置，这样做是**因为交换和移动的次数最少**，这种想法也应该是十分自然的，并且保持了完全二叉树的性质，但是此时数组并不满足最大堆的性质，我们就要进行 `shift down` 的操作使这个数组保持最大堆的性质。

`shift down` 的具体操作步骤：从 $1$ 号索引开始，如果存在右孩子，就把右孩子和左孩子比较，比出最大的那个，再和自己比较，如果比自己大，就交换位置，这样的过程直到“不小于两个孩子结点中的最大者”。

同理，我们可以写出 `shift down` 的两个版本：

Python 代码：

```python
def __shift_down(self, k):
    # 只要有左右孩子，左右孩子只要比自己大，就交换
    while 2 * k <= self.count:
        # 如果这个元素有左边的孩子
        j = 2 * k
        # 如果有右边的孩子，大于左边的孩子，就好像左边的孩子不存在一样
        if j + 1 <= self.count and self.data[j + 1] > self.data[j]:
            j = j + 1
        if self.data[k] >= self.data[j]:
            break
        self.data[k], self.data[j] = self.data[j], self.data[k]
        k = j
```

说明：当我们从 1 开始存放最大堆的元素的时候，最大堆的最后一个元素是 `data[count]`。

在完全二叉树中，如何表示有孩子？其实有左孩子就够了。这里的循环条件是 `2 * k <= count` ，等于号不能漏掉，自己手画一个完全二叉树就清楚了。

在结点存在子结点的情况下，先判断是否存在右孩子，如果存在右孩子，就一定有左孩子，然后把右孩子和左孩子比较，比出最大的那个，再和自己比较，如果比自己大，就交换位置，这样的过程直到“自己比左右两个孩子都大”为止。

和上一节 shift up 的优化的思路一样：逐渐下移的过程可以不用逐层交换，借用插入排序优化的思路，多次赋值，一次交换。于是，我们有了版本 2 。

Python 代码：

```python
def __sink(self, k):
    # 下沉
    temp = self.data[k]
    # 只要它有孩子，注意，这里的等于号是十分关键的
    while 2 * k <= self.count:
        j = 2 * k
        # 如果它有右边的孩子，并且右边的孩子大于左边的孩子
        if j + 1 <= self.count and self.data[j + 1] > self.data[j]:
            # 右边的孩子胜出，此时可以认为没有左孩子
            j += 1
        # 如果当前的元素的值，比右边的孩子节点要大，则逐渐下落的过程到此结束
        if temp >= self.data[j]:
            break
        # 否则，交换位置，继续循环
        self.data[k] = self.data[j]
        k = j
    self.data[k] = temp
```

`shift down` 是 `extract_max` 的一个子过程，有了 `shift down`，`extract_max` 函数就可以很快写出来。

Python 代码：

```python
def extract_max(self):
    if self.count == 0:
        raise Exception('堆里没有可以取出的元素')
    ret = self.data[1]
    self.data[1], self.data[self.count] = self.data[self.count], self.data[1]
    self.count -= 1
    self.__sink(1)
    return ret
```

完整代码：

Python 代码：

```python
# 通过 LeetCode 第 215 题、第 295 题测试
class MaxHeap:
    def __init__(self, capacity):
        # 我们这个版本的实现中，0 号索引是不存数据的，这一点一定要注意
        # 因为数组从索引 1 开始存放数值
        # 所以开辟 capacity + 1 这么多大小的空间
        self.data = [None for _ in range(capacity + 1)]
        # 当前堆中存储的元素的个数
        self.count = 0
        # 堆中能够存储的元素的最大数量（为简化问题，不考虑动态扩展）
        self.capacity = capacity

    def size(self):
        """
        返回最大堆中的元素的个数
        :return:
        """
        return self.count

    def is_empty(self):
        """
        返回最大堆中的元素是否为空
        :return:
        """
        return self.count == 0

    def insert(self, item):
        if self.count + 1 > self.capacity:
            raise Exception('堆的容量不够了')
        self.count += 1
        self.data[self.count] = item
        # 考虑将它上移
        self.__swim(self.count)

    def __shift_up(self, k):
        # 有索引就要考虑索引越界的情况，已经在索引 1 的位置，就没有必要上移了
        while k > 1 and self.data[k // 2] < self.data[k]:
            self.data[k // 2], self.data[k] = self.data[k], self.data[k // 2]
            k //= 2

    def __swim(self, k):
        # 上浮，与父结点进行比较
        temp = self.data[k]
        # 有索引就要考虑索引越界的情况，已经在索引 1 的位置，就没有必要上移了
        while k > 1 and self.data[k // 2] < temp:
            self.data[k] = self.data[k // 2]
            k //= 2
        self.data[k] = temp

    def extract_max(self):
        if self.count == 0:
            raise Exception('堆里没有可以取出的元素')
        ret = self.data[1]
        self.data[1], self.data[self.count] = self.data[self.count], self.data[1]
        self.count -= 1
        self.__sink(1)
        return ret

    def __shift_down(self, k):
        # 只要有左右孩子，左右孩子只要比自己大，就交换
        while 2 * k <= self.count:
            # 如果这个元素有左边的孩子
            j = 2 * k
            # 如果有右边的孩子，大于左边的孩子，就好像左边的孩子不存在一样
            if j + 1 <= self.count and self.data[j + 1] > self.data[j]:
                j = j + 1
            if self.data[k] >= self.data[j]:
                break
            self.data[k], self.data[j] = self.data[j], self.data[k]
            k = j

    def __sink(self, k):
        # 下沉
        temp = self.data[k]
        # 只要它有孩子，注意，这里的等于号是十分关键的
        while 2 * k <= self.count:
            j = 2 * k
            # 如果它有右边的孩子，并且右边的孩子大于左边的孩子
            if j + 1 <= self.count and self.data[j + 1] > self.data[j]:
                # 右边的孩子胜出，此时可以认为没有左孩子
                j += 1
            # 如果当前的元素的值，比右边的孩子节点要大，则逐渐下落的过程到此结束
            if temp >= self.data[j]:
                break
            # 否则，交换位置，继续循环
            self.data[k] = self.data[j]
            k = j
        self.data[k] = temp


if __name__ == '__main__':
    max_heap = MaxHeap(6)
    max_heap.insert(3)
    print(max_heap.data[1])
    max_heap.insert(5)
    print(max_heap.data[1])
    max_heap.insert(1)
    print(max_heap.data[1])
    max_heap.insert(8)
    print(max_heap.data[1])
    max_heap.insert(7)
    print(max_heap.data[1])
    max_heap.insert(12)

    while not max_heap.is_empty():
        print('取出', max_heap.extract_max())
```

到这里，我们就可以通过“最大堆”实现排序功能了。“最小堆”可以如法炮制。

我们已经实现了最大堆的**入队**和**出队**两个基本操作，我们完全通过直接输出元素来检验一下，自己写出的最大堆是否符合最大堆的性质。因为每一次从最大堆取出的总是数组中最大的元素，所以可以将最大堆用于排序。

## 优先队列的应用

1、多路归并排序

LeetCode 第 23 题：[23. Merge k Sorted Lists](https://leetcode.com/problems/merge-k-sorted-lists/description/)；

传送门：[23. 合并K个排序链表](https://leetcode-cn.com/problems/merge-k-sorted-lists/description/)；

题解：https://liweiwei1419.github.io/leetcode-solution/leetcode-0023-merge-k-sorted-lists/。

2、图论中的最小生成树算法；

3、图论中的最短路径算法；

4、哈夫曼树与哈夫曼编码；

另外，在 LeetCode 上使用堆解决的问题有：

LeetCode 第 451 题：[根据字符出现频率排序](https://leetcode-cn.com/problems/sort-characters-by-frequency)

LeetCode 第 703 题：[数据流中的第K大元素](https://leetcode-cn.com/problems/kth-largest-element-in-a-stream)

LeetCode 第 295 题：[数据流的中位数](https://leetcode-cn.com/problems/find-median-from-data-stream)

### 本文源代码

Python：[代码文件夹](https://github.com/liweiwei1419/Algorithms-Learning-Python/tree/master/heap)，Java：[代码文件夹](https://github.com/liweiwei1419/Algorithms-Learning-Java/tree/master/06-Heap/src)。

（本节完）